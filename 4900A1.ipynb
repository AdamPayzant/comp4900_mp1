{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4900A1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwvgGcimAxHP",
        "outputId": "e00d85f8-f851-4cea-9343-02021bf55828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "import sys\n",
        "from scipy.special import expit\n",
        "from math import e\n",
        "\n",
        "class Regress:\n",
        "\n",
        "    def __init__(self, features):\n",
        "        self.weights = None\n",
        "        \n",
        "    def fit(self, data, lr, y, iterations=100):\n",
        "\n",
        "        # Initialize our weights\n",
        "        if self.weights is None: self.weights = np.zeros(data.shape[1])\n",
        "\n",
        "        # Flatten the classes\n",
        "        y = y.flatten()\n",
        "\n",
        "        # Run for the number of iterations\n",
        "        for _ in range(iterations):\n",
        "            # Find the gradient of our current model state\n",
        "            grad = gradient(self.weights, data, y)\n",
        "            # Update weights by the learning rate\n",
        "            self.weights -= lr * grad\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Return the models prediction for these features\n",
        "        return int(model(x, self.weights) > 0.5)\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the models weights\n",
        "        self.weights = None\n",
        "\n",
        "def sigmoid(z):\n",
        "    # Calculate the sigmoid value for the given input\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def model(x, weights):\n",
        "    # Take the dot product of the input features and weights vectors\n",
        "    # Then return the sigmoid of this result\n",
        "    return sigmoid(np.dot(x, weights))\n",
        "\n",
        "def gradient(weights, x, y):\n",
        "    # Get the models predictions given these features\n",
        "    preds = model(x, weights)\n",
        "    # determine the gradient of these features\n",
        "    # defined as: X (sigmoid(W_k^T dot X) - Y)\n",
        "    gradient = np.dot(x.T, preds - y)\n",
        "    return gradient\n",
        "\n",
        "\n",
        "class KFold2:\n",
        "    def __init__(self, reg, k=10):\n",
        "        self.k = k\n",
        "        self.reg = reg\n",
        "    \n",
        "    def shuffle(self, df):\n",
        "        return df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    def splitAtX(self, k,x, df):\n",
        "        sizeOfSets = len(df) // k\n",
        "        training = copy.deepcopy(df)\n",
        "        validation = training[sizeOfSets*x:sizeOfSets+(sizeOfSets*x)]\n",
        "        for i in range(sizeOfSets*x,sizeOfSets+(sizeOfSets*x)):\n",
        "            training = training.drop(i)\n",
        "        self.training = training\n",
        "        self.validatation = validation\n",
        "        return training, validation\n",
        "\n",
        "    def accuEval(self, lr, iterations, shuffled):\n",
        "        err = 0\n",
        "        accurate = 0\n",
        "        inaccurate = 0\n",
        "\n",
        "        for _ in range(5):\n",
        "            count = 0\n",
        "            accurate = 0\n",
        "            inaccurate = 0\n",
        "\n",
        "            for x in range(0, self.k):\n",
        "                trainingSet, validationSet = self.splitAtX(self.k,x,shuffled)\n",
        "                trainingSetData = trainingSet.iloc[:,:-1]\n",
        "                classes = trainingSet.iloc[:,-1:]\n",
        "                self.reg.fit(trainingSetData.to_numpy(), lr, classes.to_numpy(), iterations)\n",
        "                validationSetData = validationSet.iloc[:,:-1]\n",
        "                validationSetLabel = validationSet.iloc[:,-1:]\n",
        "                validationSetLabel = validationSetLabel.to_numpy()\n",
        "                count = 0\n",
        "                for i in validationSetData.iterrows():\n",
        "                    trainingArr = []\n",
        "                    for j in range(0,len(i[1].to_numpy())):\n",
        "                        trainingArr.append(i[1].to_numpy()[j])\n",
        "                    if self.reg.predict(trainingArr) == validationSetLabel[count][0]:\n",
        "                        accurate += 1\n",
        "                    else:\n",
        "                        inaccurate += 1\n",
        "                    count += 1\n",
        "                err += inaccurate/count\n",
        "                #print(accuracyEval)\n",
        "            err = err/5\n",
        "        return err\n",
        "\n",
        "    def run(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def loadCSV(filename):\n",
        "    return pd.read_csv(filename)\n",
        "\n",
        "\n",
        "lrVals = [0.01, 0.04, 0.08, 0.1, 0.2, 0.5, 0.8]\n",
        "numIterations = [10, 40, 100, 200, 500, 1000, 5000]\n",
        "\n",
        "df = loadCSV(\"bankrupcy.csv\")\n",
        "linReg = regress.Regress(len(df.iloc[:,:-1].columns))\n",
        "kFoldData = KFold2(reg=linReg)\n",
        "shuffled = kFoldData.shuffle(df)\n",
        "for lr in lrVals:\n",
        "    for iterations in numIterations:\n",
        "        print(\"Average Error Rate: \" + str(kFoldData.accuEval(lr=lr, iterations=iterations, shuffled=shuffled)))\n",
        "        print(\"LR = \" + str(lr) + \"\\tIterations = \" + str(iterations))\n",
        "\n",
        "bestAccuracyOne = 0\n",
        "bestParametersOne = \"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Error Rate: 3.3735395555555554\n",
            "LR = 0.01\tIterations = 10\n",
            "Average Error Rate: 2.3941688888888892\n",
            "LR = 0.01\tIterations = 40\n",
            "Average Error Rate: 2.2972586666666666\n",
            "LR = 0.01\tIterations = 100\n",
            "Average Error Rate: 2.0958719999999995\n",
            "LR = 0.01\tIterations = 200\n",
            "Average Error Rate: 2.199758222222222\n",
            "LR = 0.01\tIterations = 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/regress.py:66: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Error Rate: 2.3498595555555553\n",
            "LR = 0.01\tIterations = 1000\n",
            "Average Error Rate: 2.1993102222222225\n",
            "LR = 0.01\tIterations = 5000\n",
            "Average Error Rate: 3.2404195555555555\n",
            "LR = 0.04\tIterations = 10\n",
            "Average Error Rate: 3.551786666666667\n",
            "LR = 0.04\tIterations = 40\n",
            "Average Error Rate: 3.378737777777778\n",
            "LR = 0.04\tIterations = 100\n",
            "Average Error Rate: 3.469582222222222\n",
            "LR = 0.04\tIterations = 200\n",
            "Average Error Rate: 2.7200284444444445\n",
            "LR = 0.04\tIterations = 500\n",
            "Average Error Rate: 2.8934399999999996\n",
            "LR = 0.04\tIterations = 1000\n",
            "Average Error Rate: 3.4286222222222222\n",
            "LR = 0.04\tIterations = 5000\n",
            "Average Error Rate: 3.1832462222222224\n",
            "LR = 0.08\tIterations = 10\n",
            "Average Error Rate: 3.7914168888888895\n",
            "LR = 0.08\tIterations = 40\n",
            "Average Error Rate: 3.0902186666666673\n",
            "LR = 0.08\tIterations = 100\n",
            "Average Error Rate: 3.488248888888889\n",
            "LR = 0.08\tIterations = 200\n",
            "Average Error Rate: 2.909006222222222\n",
            "LR = 0.08\tIterations = 500\n",
            "Average Error Rate: 2.8899057777777775\n",
            "LR = 0.08\tIterations = 1000\n",
            "Average Error Rate: 2.840277333333333\n",
            "LR = 0.08\tIterations = 5000\n",
            "Average Error Rate: 2.2685297777777778\n",
            "LR = 0.1\tIterations = 10\n",
            "Average Error Rate: 2.705735111111111\n",
            "LR = 0.1\tIterations = 40\n",
            "Average Error Rate: 3.171306666666667\n",
            "LR = 0.1\tIterations = 100\n",
            "Average Error Rate: 3.005582222222222\n",
            "LR = 0.1\tIterations = 200\n",
            "Average Error Rate: 3.132010666666667\n",
            "LR = 0.1\tIterations = 500\n",
            "Average Error Rate: 3.043221333333333\n",
            "LR = 0.1\tIterations = 1000\n",
            "Average Error Rate: 2.7635484444444445\n",
            "LR = 0.1\tIterations = 5000\n",
            "Average Error Rate: 3.1963804444444444\n",
            "LR = 0.2\tIterations = 10\n",
            "Average Error Rate: 3.0455537777777772\n",
            "LR = 0.2\tIterations = 40\n",
            "Average Error Rate: 2.8583822222222226\n",
            "LR = 0.2\tIterations = 100\n",
            "Average Error Rate: 2.916935111111111\n",
            "LR = 0.2\tIterations = 200\n",
            "Average Error Rate: 2.8947342222222217\n",
            "LR = 0.2\tIterations = 500\n",
            "Average Error Rate: 3.4082133333333333\n",
            "LR = 0.2\tIterations = 1000\n",
            "Average Error Rate: 2.9405368888888885\n",
            "LR = 0.2\tIterations = 5000\n",
            "Average Error Rate: 2.8981973333333335\n",
            "LR = 0.5\tIterations = 10\n",
            "Average Error Rate: 3.0745955555555553\n",
            "LR = 0.5\tIterations = 40\n",
            "Average Error Rate: 2.7363342222222222\n",
            "LR = 0.5\tIterations = 100\n",
            "Average Error Rate: 3.109475555555556\n",
            "LR = 0.5\tIterations = 200\n",
            "Average Error Rate: 3.1467662222222224\n",
            "LR = 0.5\tIterations = 500\n",
            "Average Error Rate: 2.9376639999999994\n",
            "LR = 0.5\tIterations = 1000\n",
            "Average Error Rate: 3.0698879999999997\n",
            "LR = 0.5\tIterations = 5000\n",
            "Average Error Rate: 3.286378666666667\n",
            "LR = 0.8\tIterations = 10\n",
            "Average Error Rate: 2.76096\n",
            "LR = 0.8\tIterations = 40\n",
            "Average Error Rate: 2.554126222222222\n",
            "LR = 0.8\tIterations = 100\n",
            "Average Error Rate: 2.9631715555555553\n",
            "LR = 0.8\tIterations = 200\n",
            "Average Error Rate: 2.9871004444444447\n",
            "LR = 0.8\tIterations = 500\n",
            "Average Error Rate: 3.0601386666666666\n",
            "LR = 0.8\tIterations = 1000\n",
            "Average Error Rate: 3.0179555555555555\n",
            "LR = 0.8\tIterations = 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq6RI8QgJz4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR6yGQz0FkOU",
        "outputId": "7e2eef03-c298-4324-f5c3-a437e2a2d0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}